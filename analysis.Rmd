---
title: "SARS-CoV-2 infection by PLD Bayesian regression modeling"
output: html_document
bibliography: bibliography_20210117.bibtex.bib
csl: apa.csl
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = 'center',
  cache = TRUE)

library(plyr)
library(tidyverse)

# for loading Prism data files
library(pzfx)

# for Bayesian modeling
library(brms)
library(bayesplot)
library(MPStats)
MPStats::bayesplot_theme()

# for laying out ggplot2 figures
library(patchwork)

source("scripts/regression_plot.R")
```
(Tummino, et al., 2021)  
Drug-induced phospholipidosis confounds antiviral SARS-CoV-2 drug repurposing  
Supplementary Materials XXX: Bayesian Infection by PLD regression model

## Context
Many drug repurposing screens for anti-SARS-CoV-2 activity have identified cationic amphiphilic drugs (CADs) that are known to disrupt the metabolism and transport of phospholipids in a process call phospholipidosis (PLD) (@Breiden2019-py). Do these drugs inhibit SARS-CoV-2 through phospholipidosis? PLD is a plausible mechanism of action for cell-based viral inhibition because a) SARS-CoV-2 may require access to certain enzymes in the lysosome to prime viral surface proteins for cellular entry, and b) coronaviruses remodel the endoplasmic reticulum into double membrane vesicles as sites of viral replication, which may be disrupted by phospholipidosis. However, PLD as a common mechanism of action for a wide range of drugs is problematic because it limits the shots-on-goal in translating them to the clinic, especially if they were incorrectly prioritized for alternative mechanisms of action. For example, PLD can in some cases cause mild liver toxicity or there is some evidence that among coronaviruses SARS-CoV-2 access to lysosomal enzymes may be dispensable for infection. Thus is a pressing question if CADs inhibit SARS-CoV-2 infection through PLD or not.

### Bayesian Regression Workflow
Given a given dataset of compounds, each measured for inhibition of SARS-CoV-2 infection and PLD at a range of doses, we will follow a Bayesian analysis workflow (@Gelman2020-sf, @Van_de_Schoot2020-ei), to build a series of regression models using tools from the Stan ecosystem (@Carpenter2017-pj, @Burkner2017-ww, @Vehtari2017-pw, @Gabry2017-jm, @Kay2018-kn, @Wickham2016-xy, @Wickham2019-jb, @Team2013-nq).  For each model we will,

1. Define and fit a probabilistic model, which combines a *prior* distribution over a set of parameters with the data to draw samples from *posterior* distribution over the parameters using Hamiltonian Markov Chain Monte Carlo.
2. Check for sampling convergence.
3. Use prior and posterior predictive checks to evaluate the model specification and fit.
4. Use cross validation to evaluate the generalizability of the model.
5. Assess inferences that can be made from the model.

Then, we will compare the models based on their fit of the data and inferences that can be made.


## Load data

First we will Load data from GraphPad Prism data file
```{r data-paths, dependson=c("setup")}
pzfx_fname <- "raw_data/Fig3C_correlations_and_SI_Fig8.pzfx"
pzfx::pzfx_tables(pzfx_fname)
```
In this file we have infection and PLD data for individual compounds tables 1-19 and compiled set of compounds in table 20. Each table summarizes the mean, standard deviation, and number of measurements of a treatment (drug, dose) on PLD amount as log-fold change relative to Amiodarone, and percent SARS-CoV-2 infection normalized to the buffer DMSO. Note that the PLD and infection are these are separate experiments in comparable cell systems (A549 vs. A549 with ACE2 over-expressed). Further experimental details are available in the main text.

```{r load-table, echo=FALSE, dependson=c("data-paths")}
load_table <- function(pzfx_fname, table, drug_name=NULL){
  data <- pzfx::read_pzfx(
    pzfx_fname,
    table = table) %>%
    dplyr::rename(
      dose = `[Drug] M`,
      pld_mean = `PLD Amount (Fold Change of Amiodarone)_MEAN`,
      pld_sem = `PLD Amount (Fold Change of Amiodarone)_SEM`,
      pld_n = `PLD Amount (Fold Change of Amiodarone)_N`,
      infection_mean = `% SARS-CoV-2 (Normalized to DMSO)_MEAN`,
      infection_sem = `% SARS-CoV-2 (Normalized to DMSO)_SEM`,
      infection_n = `% SARS-CoV-2 (Normalized to DMSO)_N`)
  if(!is.null(drug_name)){
    data <- data %>% dplyr::mutate(drug = drug_name, .before = 1)
  } else {
    data <- data %>%
      dplyr::rename(drug = ROWTITLE) %>%
      dplyr::mutate(drug = drug %>% stringr::str_trim())
  }
}
```

```{r load-data, dependson=c("load-tables")}
data <- dplyr::bind_rows(
  load_table(pzfx_fname, 8, "ZZY-10-051"),
  load_table(pzfx_fname, 9, "ZZY-10-061"),
  load_table(pzfx_fname, 15, "Ellipticine"),
  load_table(pzfx_fname, 19, "Ebastine"),
  load_table(pzfx_fname, 20)) %>%
  dplyr::filter(!drug %in% c("Elacridar", "Melperone")) %>%
  dplyr::mutate(drug = ifelse(drug == "Amiodarone", "Amiodarone_b1", drug))

#### ADD BATCH 3 DATA ####
pld_batch3_fname <- "raw_data/PLD_Batch3_pooled_analysis.pzfx"
infection_batch3_fname <- "raw_data/raw_viral_RNA_normalized_for_matt.pzfx"

load_pld_batch3 <- function(fname, table,  drug_name=NULL) {
  data <- pzfx::read_pzfx(fname, table = table) %>%
    dplyr::rename(dose = `Drug concentration (mM)`) %>%
    dplyr::mutate(dose = dose * 1e-6) %>%
    dplyr::mutate(dose = ifelse(dose == 1e-12, 0, dose)) %>%
    dplyr::select(dose, tidyselect::starts_with("Efficacy")) %>%
    tidyr::pivot_longer(
      cols = tidyselect::starts_with("Efficacy"),
      names_to =c("measurement", "replica"),
      names_sep = "_") %>%
    dplyr::group_by(dose) %>%
    dplyr::summarize(
      pld_mean = mean(value/100),
      pld_sem = sd(value/100) / sqrt(3),
      pld_n = dplyr::n())

  if(!is.null(drug_name)){
    data <- data %>% dplyr::mutate(drug = drug_name, .before = 1)
  } else {
    data <- data %>%
      dplyr::rename(drug = ROWTITLE) %>%
      dplyr::mutate(drug = drug %>% stringr::str_trim())
  }
}

infection_batch3 <- readxl::read_excel("raw_data/Baseline-corrected of RT-qPCR_new_PLD_set.xlsx") %>%
  dplyr::select(-`Baseline-Control`) %>%
  dplyr::rename(dose = `[Drug] M`) %>%
  tidyr::pivot_longer(
    cols = -dose,
    names_to = c("drug", "measurement"),
    names_sep = "_") %>%
  dplyr::mutate(drug = drug %>% stringr::str_replace(" \\(.*\\)$", "")) %>%
  dplyr::mutate(measurement = measurement %>% stringr::str_to_lower()) %>%
  tidyr::pivot_wider(
    id_cols = c(drug, dose),
    names_from = "measurement",
    names_prefix = "infection_") %>%
  dplyr::mutate(infection_n = 3)

amiodarone_batch3 <- load_pld_batch3(pld_batch3_fname, table = 30, "Amiodarone_b3") %>%
  dplyr::mutate(dose = signif(dose, 1)) %>%
  dplyr::full_join(
    data %>%
      dplyr::filter(drug == "Amiodarone_b1") %>%
      dplyr::mutate(drug = "Amiodarone_b3") %>%
      dplyr::mutate(dose = signif(dose, 1)) %>%
      dplyr::select(drug, dose, infection_mean, infection_sem, infection_n),
    by = c("drug", "dose"))

pld_batch3 <- dplyr::bind_rows(
  load_pld_batch3(pld_batch3_fname, table = 31, "Azithromycin"))


data_batch3 <- dplyr::left_join(
  pld_batch3 %>% dplyr::mutate(dose = signif(dose, 1)),
  infection_batch3 %>%
    dplyr::filter( drug %in% c("Azithromycin")) %>%
    dplyr::mutate(dose = signif(dose, 1)),
  by = c("drug", "dose")) %>%
  dplyr::bind_rows(amiodarone_batch3)


data <- data %>% dplyr::bind_rows(data_batch3)

data %>% dplyr::glimpse()
```


# add batch 3 data
```{r load-prospective-data}

prospective_pld_batch3 <- dplyr::bind_rows(
  load_pld_batch3(pld_batch3_fname, table = 33, "Duloxetine"),
  load_pld_batch3(pld_batch3_fname, table = 35, "Fluspirilene"),
  load_pld_batch3(pld_batch3_fname, table = 36, "Methdilazine"),
  load_pld_batch3(pld_batch3_fname, table = 38, "Thiethylperazine"),
  load_pld_batch3(pld_batch3_fname, table = 39, "Toremifene"))

prospective_data <- prospective_pld_batch3 %>%
  dplyr::mutate(dose = signif(dose, 1)) %>%
  dplyr::inner_join(
    infection_batch3 %>%
      dplyr::mutate(dose = signif(dose, 1)) %>%
      dplyr::filter(
        drug %in% c("Duloxetine", "Fluspirilene", "Methdilazine", "Thiethylperazine", "Toremifene"),
        !(drug == "Fluspirilene" & dose == 1e-5),
        !(drug == "Thiethylperazine" & dose == 1e-5)),
    by = c("drug", "dose")) %>%
  dplyr::filter(!is.na(dose))
    

data_all <- dplyr::bind_rows(data, prospective_data)
```

Note that some compounds tested do not substantially cause phospholipidosis and could potentially be excluded from the analysis. These compounds cause less than %25 PLD relative to Amiodarone over all doses tested:
```{r drug-pld-max, dependson=c("load-data"), echo=FALSE}
data %>%
  dplyr::group_by(drug) %>%
  dplyr::arrange(desc(pld_mean)) %>%
  dplyr::slice(1) %>%
  dplyr::ungroup() %>%
  dplyr::filter(pld_mean < .25) %>%
  dplyr::arrange(pld_mean) %>%
  dplyr::transmute(Drug=drug, `Dose (uM)` = dose *1e6, `Max PLD %` = paste0((pld_mean*100) %>% signif(2), " %"))
```


# Fit Models

## Regression parameterization
We will now fit a series of models for infection as a function of PLD. Virus quantification via RT-qPCR capture complex infection dynamics. To facilitate identifying the influence of PLD, we will compare three parameterizations of the the infection, log, sqrt-log, and log-log:
```{r response-param, dependson=c("load-data"), echo=FALSE, fig.height=6, fig.width=4}

response_param <- dplyr::bind_rows(
  data %>% dplyr::mutate(
    parameterization = "log",
    infection = infection_mean),
  data %>% dplyr::mutate(
    parameterization = "logsqrt",
    infection = sqrt(data$infection_mean)),
  data %>% dplyr::mutate(
    parameterization = "loglog",
    infection = log(data$infection_mean))) %>%
  dplyr::arrange(dose)
   
p1 <- ggplot2::ggplot(response_param) +
  ggplot2::theme_bw() +
  ggplot2::geom_path(
    mapping = ggplot2::aes(
      x = log(pld_mean),
      y = infection,
      group = drug)) +
  ggplot2::geom_point(
    mapping = ggplot2::aes(
      x = log(pld_mean),
      y = infection)) +
  ggplot2::facet_wrap(
    ~parameterization,
    ncol = 1,
    scales = "free") +
  scale_pld_x +
  ggplot2::scale_y_continuous("Parameterization of % Infection")

p2 <- ggplot2::ggplot(response_param) +
  ggplot2::theme_bw() +
  ggplot2::theme(
    axis.title.y=element_blank(),
    axis.text.y=element_blank(),
    axis.ticks.y=element_blank()) +
  ggplot2::geom_density(
    mapping = ggplot2::aes(
      x = infection),
    fill = "darkgrey") +
  ggplot2::facet_wrap(
    ~parameterization,
    ncol = 1,
    scales = "free") +
  ggplot2::coord_flip() +
  ggplot2::scale_y_continuous("Density") +
  ggplot2::scale_x_continuous("")


plot <- (p1 + p2)
plot + patchwork::plot_annotation(
  title = 'Parameterizations of % Infection')
```
This shows that the all three parameterizations are reasonable but that the log-sqrt parameterization stabilizes the variance at the high and low values of infection.

## Fit flat regression model
Now we will fit a flat regression model to use a a model for no dependence of `pld`{.R} on `infection`{.R}. We'll go through in detail how to interpret the plots for this model, so we can re-use them in fitting later models.
```{r model-flat, dependson=c("load-data"), message=FALSE, warning=FALSE, cache=TRUE, echo=TRUE, results='hide'}
model_logsqrt_flat <- brms::brm(
  formula = sqrt(infection_mean) ~ 1,
  prior = c(
    brms::prior(student_t(3, 5, 5),  class = "Intercept"),
    brms::prior(student_t(3, 0, 5),  class = "sigma")),
  data = data,
  iter = 20000,
  cores = 4)
model_logsqrt_flat$name <- "flat"
```
Here is a summary of the model fit, at this point we're looking primarily for the quality of the simulation. There are three areas to consider.

   1. The Rhat should be close 1 indicating the chains are not exploring the same regions of parameter space and not getting stuck.
   2. The Bulk and Tail effective sample sizes (Bulk_ESS, Tail_ESS) should be > 1000.
   3. There are no divergences. The NUTs algorithm can detect when the parameter space is difficult to sample.
   
If these areas are not all satisfied, then either run the simulation for longer, or reparameterize the model. We'll return below to interpret model specification and parameter estimates.
```{r model-flat-summary, dependson=c("model-flat"), echo=FALSE}
model_logsqrt_flat
```

### Check for convergence
Since the Rhat is close to 1 and bulk_ESS and tail_ESS are > 2500, it looks to have converged. To further check convergence we will evaluate the traceplot, which shows the sampled for each parameter and each chain across the MCMC trajectories. We're looking for convergence across the sampling.
```{r model-flat-traceplot, dependson=c("model-flat"), echo=FALSE, fig.width = 8, fig.height=2}
model_logsqrt_flat %>% MPStats::traceplot()
```

and the rank histogram. The idea here is that if the simulation has converged, then the rank of each sample should be uniform, which can be visually assessed by making a histogram.   
```{r model-flat-rankplot, dependson=c("model-flat"), echo=FALSE, fig.width = 8, fig.height=2}
model_logsqrt_flat %>% MPStats::rankplot()
```

### Check specification of priors
Well specified priors should incorporate any domain knowledge ranging from uninformative, weakly informative, to strongly informative. Further the extent the inferences are sensitive to the priors should be clear.

```{r model-flat-prior-posterior-draws, dependson=c("model-flat"), message = FALSE, warning = FALSE, echo = FALSE, results='hide', fig.width = 8, fig.height=2.5}
MPStats::prior_posterior_plot(model = model_logsqrt_flat) +
  ggplot2::theme(legend.position = c(.9, .7))
```

### Check quality of model fit
To assess the model fit we will use leave-one-out cross validation, that is re-fitting the model for each (drug, dose) and measuring the posterior probability of the held out sample. This is a more reliable way to compare models and estimate how well the model will generalize, which we'll return to after we defined all the models. To make this more computationally tractable, we use a method called Pareto smoothed importance sampling to approximate it by re-sampling from the posterior distribution. To interpret these scores, we want the the expected log pointwise predictive density for a new dataset (`elpd_loo`{.R}) to be large, and `p_loo`{.R}, the p_loo is the difference between `elpd_loo`{.R} and the non-cross-validated log posterior predictive density to be small. `p_loo`{.R} can be interpreted as the effective number of parameters, and ideally it should be less than the total number of samples (`p_loo < N`{.R}) and less than the actual number of parameters `p_loo < p`{.R} where `p` is the number of parameters in the model. A rule of thumb for model selection is that all else being equal, the `elpd_loo`{.R} should be twice or four times the standard deviation better to prefer a different model.

An interesting feature of using leave-one-out cross validation, is it can be used detect outliers as `pareto_k`{.R} estimates for each point. If there were any, they would show up as values `> .5`{.R} or worse here.
```{r model-flat-criteria, dependson=c("model-flat"), message=FALSE, warning=FALSE, echo=FALSE, cache=TRUE}
model_logsqrt_flat <- model_logsqrt_flat %>% 
  brms::add_criterion("loo") %>%
  brms::add_criterion(
    criterion = "kfold",
    folds = loo::kfold_split_grouped(
      K = data$drug %>% unique() %>% length(),
      x = data$drug)) %>%
  brms::add_criterion("loo_R2")
model_logsqrt_flat$criteria$loo
```


We can also estimate the leave-one-drug-out cross validation, where the question is how well the model generalizes to *new drugs*. 
```{r model-flat-criteria-kfold, dependson=c("model-flat-criteria"), message=FALSE, warning=FALSE, echo=FALSE}
model_logsqrt_flat$criteria$kfold
```




A way to visualize if there is model mis-specification is through a posterior predictive checks. The idea is that if the model fits the data, we should have a hard time distinguishing the data from fake data generated from the fit model. In the upper two plots, samples generated from the model are shown in thin blue lines and the actual data is the thick black line. In the upper left plot, the x-axis is the response in this case the transformed percent infection, and in the right, the x-axis has been stretched and compressed so the samples from the model are approximately uniform (they dip down at the edges because of uncertainty in the model). For more details on posterior predictive checks and these plots see (Gabry2019-ra). Below, it shows the average prediction error as a function of the response. For the flat model, the further above or below the mid-line, the worse the error. 
```{r model-flat-ppc, dependson=c("model-flat-criteria"), message=FALSE, warning=FALSE, echo=FALSE}
pp1 <- model_logsqrt_flat %>% brms::pp_check(nsamples = 50)
pp2 <- model_logsqrt_flat %>% brms::pp_check("loo_pit_overlay", nsamples = 50)
pp3 <- model_logsqrt_flat %>% brms::pp_check(type='error_scatter_avg') +
  ggplot2::theme_bw() +
  scale_infection_y +
  ggplot2::coord_flip()
pp3$layers <- c(
  ggplot2::geom_vline(xintercept = 0, color="grey20"),
  pp3$layers)
(pp1 | pp2) / pp3
```

### Interpret the model
The pairs plot shows if there is any correlation in the among the parameters. This can help interpret the model, or indicate alternative models or paremterizations. This show very little correlation between the intercept (the b_ prefix comes from the brms framework).
```{r model-flat-pairs, dependson=c("model-flat"), dev="png", echo=FALSE}
model_logsqrt_flat %>% MPStats::pairsplot()
```

Now we will plot draws from the fitted model on scatter plot of the infection vs PLD data  
```{r regression-flat, dependson=c("model-flat"), echo=FALSE}
regression_plot(model_logsqrt_flat)
```


## Fit linear regression model
Now we will fit a linear regression model for infection_mean by pld_mean.
```{r model-linear, dependson=c("load-data"), message=FALSE, warning=FALSE, echo=TRUE, results='hide', cache=TRUE}
model_logsqrt_linear <- brms::brm(
  formula = sqrt(infection_mean) ~ log(pld_mean),
  prior = c(
    brms::prior(student_t(3, 5, 5),  class = "Intercept"),
    brms::prior(student_t(3, 0, 5),  class = "sigma"),
    brms::prior(normal(0, 10),  class = "b")),
  iter = 20000,
  cores = 4,
  data = data,
  verbose = FALSE)
model_logsqrt_linear$name <- "linear"

model_logsqrt_linear_all <- brms::brm(
  formula = sqrt(infection_mean) ~ log(pld_mean),
  prior = c(
    brms::prior(student_t(3, 5, 5),  class = "Intercept"),
    brms::prior(student_t(3, 0, 5),  class = "sigma"),
    brms::prior(normal(0, 10),  class = "b")),
  iter = 20000,
  cores = 4,
  data = data_all,
  verbose = FALSE)
model_logsqrt_linear_all$name <- "linear_all"
```

```{r model-linear-summary, dependson=c("model-linear"), echo=FALSE}
model_logsqrt_linear
```

### Check for convergence
```{r model-linear-traceplot, dependson=c("model-linear"), echo=FALSE, fig.width=8, fig.heigh=4}
model_logsqrt_linear %>% MPStats::traceplot()
```

```{r model-linear-rankplot, dependson=c("model-linear"), echo=FALSE, fig.width=8, fig.heigh=4}
model_logsqrt_linear %>% MPStats::rankplot()
```

### Check specification of priors
```{r model-linear-prior-posterior-draws, dependson=c("model-linear"), echo=FALSE, message=FALSE, results='hide', fig.width=8, fig.height=2}

MPStats::prior_posterior_plot(model = model_logsqrt_linear) +
  ggplot2::theme(legend.position = c(.92, .5))
```


### Check quality of model fit
leave-one-out cross validation
```{r model-linear-criteria, dependson=c("model-linear"), message=FALSE, warning=FALSE, echo=FALSE, cache=TRUE}
model_logsqrt_linear <- model_logsqrt_linear %>% 
  brms::add_criterion("loo") %>%
  brms::add_criterion(
    criterion = "kfold",
    folds = loo::kfold_split_grouped(
      K = data$drug %>% unique() %>% length(),
      x = data$drug)) %>%
  brms::add_criterion("loo_R2")
model_logsqrt_linear$criteria$loo

```


Leave-one-drug-out cross validation:
```{r model-linear-criteria-kfold, dependson=c("model-linear-criteria"), message=FALSE, warning=FALSE, echo=FALSE}
model_logsqrt_linear$criteria$kfold
```



```{r model-linear-ppc, dependson=c("model-linear-criteria"), message=FALSE, warning=FALSE, echo=FALSE}
pp1 <- model_logsqrt_linear %>% brms::pp_check(nsamples = 50)
pp2 <- model_logsqrt_linear %>% brms::pp_check("loo_pit_overlay", nsamples = 50)
pp3 <- model_logsqrt_linear %>% brms::pp_check(type='error_scatter_avg') +
  ggplot2::theme_bw() +
  scale_infection_y +
  ggplot2::coord_flip()
pp3$layers <- c(
  ggplot2::geom_vline(xintercept = 0, color="grey20"),
  pp3$layers)
(pp1 | pp2) / pp3
```

### Interpret the model
```{r model-linear-pairs, dependson=c("model-linear"), dev="png", echo=FALSE, fig.height=5, fig.width=5}
model_logsqrt_linear %>% MPStats::pairsplot()
```

Now we will plot draws from the fitted model on scatter plot of the infection vs PLD data  
```{r regression-linear, dependson=c("model-linear"), echo=FALSE, fig.width = 10, fig.height = 6}
regression_plot(model_logsqrt_linear)
```

## Fit sigmoid2 regression model
```{r model-sigmoid2, dependson=c("load-data"), echo=FALSE, echo=TRUE, results='hide', message=FALSE, cache=TRUE}
model_logsqrt_sigmoid2 <- brms::brm(
  formula = brms::brmsformula(
    sqrt(infection_mean) ~ 10*inv_logit(hill*4/10*(log(pld_mean) - ic50)),
      ic50 + hill ~ 1,
      nl=TRUE),
  prior = c(
    brms::prior(normal(-1, 5), nlpar="ic50"),
    brms::prior(normal(-7, 2), nlpar="hill")),
  inits=function(){
    list(
      ic50=as.array(-1),
      hill=as.array(rnorm(1, -7, 3)))},
  iter=20000,
  cores = 4,
  data = data)
model_logsqrt_sigmoid2$name <- "sigmoid2"
```

```{r model-sigmoid2-summary, dependson=c("model-sigmoid2"), echo=FALSE}
model_logsqrt_sigmoid2
```

### Check for convergence
```{r model-sigmoid2-traceplot, dependson=c("model-sigmoid2"), echo=FALSE, fig.width=8, fig.height=3.5}
MPStats::traceplot(model_logsqrt_sigmoid2)
```

```{r model-sigmoid2-rankplot, dependson=c("model-sigmoid2"), echo=FALSE, fig.width=8, fig.height=3.5}
MPStats::rankplot(model_logsqrt_sigmoid2)
```

### Check specification of priors
```{r model-sigmoid2-prior-posterior-draws, dependson=c("model-sigmoid2"), echo=FALSE, message=FALSE, results='hide', fig.width=8, fig.height=2.5}
MPStats::prior_posterior_plot(model = model_logsqrt_sigmoid2) +
  ggplot2::theme(legend.position = c(.9, .4))
```


### Check quality of model fit
Leave-one-out cross validation
```{r model-sigmiod2-criteria, dependson=c("model-sigmoid2"), message=FALSE, warning=FALSE, echo=FALSE, cache=TRUE}
model_logsqrt_sigmoid2 <- model_logsqrt_sigmoid2 %>% 
  brms::add_criterion("loo") %>%
  brms::add_criterion(
    criterion = "kfold",
    folds = loo::kfold_split_grouped(
      K = data$drug %>% unique() %>% length(),
      x = data$drug)) %>%
  brms::add_criterion("loo_R2")
model_logsqrt_sigmoid2$criteria$loo
```


Leave-one-drug-out cross validation
```{r model-sigmoid2-criteria-kfold, dependson=c("model-sigmoid2-criteria"), message=FALSE, warning=FALSE, echo=FALSE}
model_logsqrt_sigmoid2$criteria$kfold
```



```{r model-sigmoid2-ppc, dependson=c("model-sigmoid2-criteria"), message=FALSE, warning=FALSE, echo=FALSE}
pp1 <- model_logsqrt_sigmoid2 %>% brms::pp_check("loo_pit_overlay", nsamples = 50)
pp2 <- model_logsqrt_sigmoid2 %>% brms::pp_check(nsamples = 50)
pp3 <- model_logsqrt_sigmoid2 %>% brms::pp_check(type='error_scatter_avg') +
  ggplot2::theme_bw() +
  scale_infection_y +
  ggplot2::coord_flip()
pp3$layers <- c(
  ggplot2::geom_vline(xintercept = 0, color="grey20"),
  pp3$layers)

(pp1 | pp2) / pp3
```

```{r model-sigmoid2-predictive-error, dependson=c("model-sigmoid2", "load-prospective-data"), warnings=FALSE}

z <- model_logsqrt_sigmoid2 %>%
  brms::predictive_error(
    newdata = prospective_data)

z <- model_logsqrt_sigmoid2 %>%
  residuals(
    newdata = prospective_data,
    method = "posterior_predict")

prospective_data %>%
  dplyr::bind_cols(as.data.frame(z)) %>%
  dplyr::mutate(infection_est = Estimate*Estimate) %>%
  dplyr::select(-pld_n, -infection_n) %>%
  dplyr::mutate(across(3:11, signif, 3)) %>%
  dplyr::arrange(pld_mean) %>%
  data.frame()

```


```{r regression-sigmoid2, dependson=c("model-sigmoid2"), echo=FALSE, fig.width = 10, fig.height = 6}
model_logsqrt_sigmoid2 %>% regression_plot()
```


## Compare all models
```{r gather-models, dependson=c("model-flat", "model-linear", "model-spline", "model-sigmoid4", "model-sigmoid2"), echo=FALSE, results='hide'}
models <- tibble::tibble( model = list(
  model_logsqrt_flat,
  model_logsqrt_linear,
  model_logsqrt_sigmoid2)) %>%
  dplyr::mutate(model_name = lapply(model, function(m){m$name}) %>% unlist(), .before = 1)

models %>%
  dplyr::rowwise() %>%
  dplyr::do({
    model_name <- .$model_name
    model <- .$model
    assertthat::assert_that(!is.null(model$name), msg = "Model name is null")
    assertthat::assert_that(!is.null(model$criteria$loo), msg = paste0("loo is null for model ", model_name))
    assertthat::assert_that(!is.null(model$criteria$loo_R2), msg = paste0("loo_R2 is null for model ", model_name))
    assertthat::assert_that(!is.null(model$criteria$kfold), msg = paste0("kfold is null for model ", model_name))
    data.frame()
    })
```

```{r regression-all-fits, dependson=c("gather-models"), echo=FALSE, fig.width = 10, fig.height = 4}

model_draws <- models %>%
  dplyr::rowwise() %>%
  dplyr::do({
    model <- .$model
    data %>% tidybayes::add_fitted_draws(
      model,
      n=40) %>%
      dplyr::mutate(model = model$name)
  }) %>%
  dplyr::ungroup()

format_R2 <- function(model){
  paste0(
    'R^2~"="~',
    model$criteria$loo_R2 %>% mean() %>% signif(2),
    '~" ["*', model$criteria$loo_R2 %>% quantile(0.025) %>% signif(2),
    '*", "*', model$criteria$loo_R2 %>% quantile(0.975) %>% signif(2),
    '*"]"')
}

R2_scores <- models %>%
  dplyr::transmute(
    label = lapply(model, format_R2),
    model = model_name)


args <- models$model
args <- append(args, values = list(criterion = "loo"))
args <- append(args, values = list(model_names = models$model_name))
names(args)[1] <- "x"
elpd_diff <- do.call(brms::loo_compare, args) %>%
  data.frame() %>%
  tibble::rownames_to_column(var = "model") %>%
  dplyr::transmute(
    model = model %>% stringr::str_replace("model_logsqrt_", ""),
    label = paste0('"elpd"["diff"]~"="~', signif(elpd_diff, 2), '~"+/-"~', signif(se_diff, 2)))


ggplot2::ggplot(
  data = data) +
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position = "bottom") +
  ggplot2::theme(legend.key.height=unit(.9,"line")) +
  ggplot2::guides(shape = ggplot2::guide_legend(ncol = 7)) +
  ggplot2::coord_cartesian(
    xlim = log(c(min(data$pld_mean), 1.5)),
    ylim = sqrt(c(0, c(max(data$infection_mean) + 8)))) +
  ggplot2::geom_line(
    data = model_draws,
    mapping = ggplot2::aes(
      x = log(pld_mean),
      y = .value,
      group = .draw),
    alpha = .1,
    color = "blue") +
  ggplot2::geom_point(
    mapping = ggplot2::aes(
      x = log(pld_mean),
      y = sqrt(infection_mean),
      shape = drug)) +
  ggplot2::scale_x_continuous(
    "% PLD of Amiodarone",
    breaks = log(c(.15, .25, .50, 1)),
    labels = c("15", "25", "50", "100"),
    expand = c(.01, .01)) +
  ggplot2::scale_y_continuous(
    "% SARS-CoV-2 (Normalized to DMSO)",
    breaks = sqrt(c(0, 10, 50, 100, 150)),
    labels = c("0", "10", "50", "100", "150"),
    expand = c(0, .01)) +
  ggplot2::scale_shape_manual(
    "Drug", values = 1:length(unique(data$drug))) +
  MPStats::geom_indicator(
    data = R2_scores,
    mapping = ggplot2::aes(indicator = label),
    group = 1,
    xpos = "right",
    ypos = "top",
    parse = TRUE) +
  MPStats::geom_indicator(
    data = elpd_diff,
    mapping = ggplot2::aes(indicator = label),
    group = 3,
    xpos = "right",
    ypos = "top",
    parse = TRUE) +
  ggplot2::facet_wrap(facets = ggplot2::vars(model))
```


Compare based on leave-one-out cross validation
```{r model-compare-loo, dependson=c("gather-models"), echo=FALSE}
args <- models$model
args <- append(args, values = list(criterion = "loo"))
args <- append(args, values = list(model_names = models$model_name))
names(args)[1] <- "x"
do.call(brms::loo_compare, args)

```

Compare based on leave-drug-out cross validation
```{r model-compare-kfold, dependson=c("gather-models"), echo=FALSE}
args <- models$model
args <- append(args, values = list(criterion = "kfold"))
args <- append(args, values = list(model_names = models$model_name))
names(args)[1] <- "x"
do.call(brms::loo_compare, args)
```


```{r model-model-weights-kfold, dependson=c("gather-models"), echo=FALSE}
model_weights <- models$model %>%
  lapply(function(m){m$criteria$kfold$pointwise[,"elpd_kfold"]}) %>%
  do.call(cbind, .) %>%
  loo::stacking_weights()
attr(model_weights, "names") <- models$model_name
model_weights
```


# Session Info
For reproducibility, here is information about the R version and loaded packages
```{r session-info}
sessionInfo()
```

# References
